{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a2gw-jJrtAU",
        "colab_type": "code",
        "outputId": "94e0414e-ad8f-434a-9863-b136d5197325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import math\n",
        "import re\n",
        "import numpy as np\n",
        "from nltk.util import ngrams\n",
        "\n",
        "import gensim\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Dense, Activation, SimpleRNN, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.utils.data_utils import get_file"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJV_A5ZMs3Af",
        "colab_type": "code",
        "outputId": "c0c0c962-c169-4393-8521-aeec04b3c83d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/ryanmcdermott/trump-speeches/master/speeches.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-06 19:36:47--  https://raw.githubusercontent.com/ryanmcdermott/trump-speeches/master/speeches.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 924745 (903K) [text/plain]\n",
            "Saving to: ‘speeches.txt’\n",
            "\n",
            "\rspeeches.txt          0%[                    ]       0  --.-KB/s               \rspeeches.txt        100%[===================>] 903.07K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2019-10-06 19:36:47 (38.3 MB/s) - ‘speeches.txt’ saved [924745/924745]\n",
            "\n",
            "--2019-10-06 19:36:50--  https://raw.githubusercontent.com/ryanmcdermott/trump-speeches/master/speeches.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 924745 (903K) [text/plain]\n",
            "Saving to: ‘speeches.txt.1’\n",
            "\n",
            "speeches.txt.1      100%[===================>] 903.07K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2019-10-06 19:36:50 (36.0 MB/s) - ‘speeches.txt.1’ saved [924745/924745]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR869ktk38cG",
        "colab_type": "text"
      },
      "source": [
        "**Text Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbqZ_IcSvUSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('speeches.txt') as f:\n",
        "  text = f.read()\n",
        "lower_text=nltk.sent_tokenize(text.lower())\n",
        "sentences=[]\n",
        "for line in lower_text:\n",
        "  if re.search(r'[a-z0-9]', line):\n",
        "    l=re.sub(r'[^a-z0-9]',\" \", line)\n",
        "  sentences.append(l)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2F2AJx234no",
        "colab_type": "text"
      },
      "source": [
        "**Train Test Split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evsALZ5b4P7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = sentences[:math.ceil(0.8*len(sentences))]\n",
        "test = sentences[math.ceil(0.8*len(sentences)):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDS88aLf3sFB",
        "colab_type": "text"
      },
      "source": [
        "**Classic Modelling N grams**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHL-AGsW8nbo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Ngram_model(n, data):\n",
        "  ngram_list=[]\n",
        "  for sentence in data:\n",
        "    sentence=nltk.word_tokenize(sentence)\n",
        "    padded_sent = list(['<s>']+sentence+['</s>'])\n",
        "    ngram_list.extend(list(ngrams(padded_sent, n=n)))\n",
        "  return ngram_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaETa0beHUTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Freq_Dist(ngram_list):\n",
        "  freq=nltk.FreqDist(ngram_list)\n",
        "  freq_dist={}\n",
        "  for key in freq:\n",
        "    freq_dist[key]=freq[key]\n",
        "  return freq_dist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01Nt8_GBUPjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MLE_dict(n, data):\n",
        "  mle_dict={}\n",
        "  l1=Ngram_model(n, data)\n",
        "  f1=Freq_Dist(l1)\n",
        "  if(n!=1):\n",
        "    l2=Ngram_model(n-1, data)\n",
        "    f2=Freq_Dist(l2)\n",
        "    for key in f1:\n",
        "      x=(' '.join(key))\n",
        "      y=f1[key]/f2[key[:-1]]\n",
        "      mle_dict[x]=y\n",
        "  else:\n",
        "    for key in f1:\n",
        "      x=(' '.join(key))\n",
        "      y=f1[key]/len(l1)\n",
        "      mle_dict[x]=y\n",
        "  return mle_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8HpamywqiAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Generator(mle_dict):\n",
        "  sentence=[]\n",
        "  pvalues=np.array([mle_dict[key] for key in mle_dict])\n",
        "  pvalues=pvalues/pvalues.sum()\n",
        "  while(True):\n",
        "    poss=list(np.random.multinomial(20, pvalues))\n",
        "    start=list(mle_dict.keys())[poss.index(max(poss))]\n",
        "    if '<s>' in start:\n",
        "      break\n",
        "    else:\n",
        "      pass\n",
        "  sentence=sentence+start.split(' ')\n",
        "  while(True):\n",
        "    poss=list(np.random.multinomial(20, pvalues))\n",
        "    move=list(mle_dict.keys())[poss.index(max(poss))]\n",
        "    if('</s>' not in move and '<s>' not in move):\n",
        "      sentence=sentence+move.split(' ')\n",
        "      pass\n",
        "    elif('</s>' in move):\n",
        "      sentence=sentence+move.split(' ')\n",
        "      break\n",
        "    \n",
        "  return ' '.join(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMi2Bf8VqiRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Perplexity(n, mle_dict, test):\n",
        "  ngram_test=Ngram_model(n, test)\n",
        "  perplexity=0\n",
        "  N=len(ngram_test)\n",
        "  m=min(list(mle_dict.values()))\n",
        "  for key in ngram_test:\n",
        "    if key in mle_dict:\n",
        "      perplexity=perplexity-(math.log(mle_dict(key))/N)\n",
        "    else:\n",
        "      perplexity=perplexity-((math.log(m))/N)\n",
        "  perplexity=math.exp(perplexity)\n",
        "  return perplexity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7AhkUmA3V4c",
        "colab_type": "text"
      },
      "source": [
        "**Perplexity of N gram Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEVfV8p80A7q",
        "colab_type": "code",
        "outputId": "a3f5842b-d4bc-48a1-f993-722e880902d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "for n in range(1, 5):\n",
        "  mle=MLE_dict(n, train)\n",
        "  p=Perplexity(n, mle, test)\n",
        "  print(\"Perplexity of \"+str(n)+\"-gram : \"+str(p))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perplexity of 1-gram : 167970.00000018327\n",
            "Perplexity of 2-gram : 13120.999999960633\n",
            "Perplexity of 3-gram : 1893.0000000043613\n",
            "Perplexity of 4-gram : 719.0000000017544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDH7oAQc7umV",
        "colab_type": "text"
      },
      "source": [
        "**Observation : Perplexity of unigram > bigram > trigram > quadgram**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy2R_vD93ky7",
        "colab_type": "text"
      },
      "source": [
        "**Random Text Generation of N gram Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14LQAJZRa52k",
        "colab_type": "code",
        "outputId": "cfabbab5-d627-4088-ad44-c6654d7a11ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "for n in range(1, 5):\n",
        "  mle=MLE_dict(n, train)\n",
        "  print(\"Generation text : \"+str(n)+\"-gram\")\n",
        "  print('')\n",
        "  for i in range(5):\n",
        "    print(Generator(mle))\n",
        "  print('')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generation text : 1-gram\n",
            "\n",
            "<s> </s>\n",
            "<s> </s>\n",
            "<s> a the to people </s>\n",
            "<s> </s>\n",
            "<s> </s>\n",
            "\n",
            "Generation text : 2-gram\n",
            "\n",
            "<s> i years </s>\n",
            "<s> i courts because with the much </s>\n",
            "<s> what executive order islamic terrorism void much repeal and consulate and rusted and liked him crooks </s>\n",
            "<s> i lied about also need kicks in pennsylvania avenue action </s>\n",
            "<s> it wants to people we watch this japanese imperialists fall </s>\n",
            "\n",
            "Generation text : 3-gram\n",
            "\n",
            "<s> civil war deficit that we me folks </s>\n",
            "<s> again the amounts of money than donald trump dollar is getting truly wealthy again re fighting here lot to be conservative and i know somebody is maybe two maybe television this morning cut social security rebuild quickly our ago pull out press he doesn weaken america he see more than can save social dollars were lost thinking of running bridge on every moneys lost </s>\n",
            "<s> horribly wasted i file my biden again criticized proposed a 2017 c this plan doing an absolutely economic assault on way especially for have islamic terrorists defending must pay our infrastructure of in 16 and straightened it out many websites </s>\n",
            "<s> logic was dangerous idea that quick on his every corner </s>\n",
            "<s> cause abraham my patients are i been saying there holding guns s falling apart stuff that isis president get away kicks in in fanaticism thousands of did something you to steal government steal government secrets peace treaty with david and everybody dollar is getting direction for our sadly i was an army tank are closing up the 1940s we what that means like small time words of president you did that s isis </s>\n",
            "\n",
            "Generation text : 4-gram\n",
            "\n",
            "<s> i would say ago but now they have i been saying ah ah i can is about one third be a better place and medicaid without cutting secrets with cyber attacks said i have more reports on bridges and to myself you know just a very short want to work they a bridge on every respect for steve king new china believe it mean you will see made that s not laguardia where the runways look at kennedy airport state remains the true i have done so into the main terminal you ve created so is desperately in need serious trouble because we national interest for honoring so why aren t in kenya and tanzania for steve king and obama a year ago ve all heard that people are closing up besides america are spending moving from here not fact my pilot said and challengers think they conservative actually very conservative from mistakes in iraq are always bent rusted really test the mettle can have anything coming in from qatar and that he made that everybody shares or wants policy veered badly off are ranked better than have 2 trillion and even care about us and if i win saying thank you very a teleprompter because we nazis and japanese imperialists <s> no deal </s>\n",
            "<s> nothing ever happens want syria to fall changer that we have as everyone knows is so it happened and tremendous numbers of deals our country great again has been with us thousands of television sets winning winning the country in iraq very proudly t even respect us which they like to a new vision for 52s in combat missions before i came in i ll probably be doesn t work </s>\n",
            "<s> everything is read about 1 3 million remember when the president are using and i have known the result asleep and that s we will win our t close the deal walking right in front and getting rid of fair because it was strongly it s very and this isn t situation in afghanistan we and get a declaratory of us but after play that would be t even respect us social security can be <s> very simple </s>\n",
            "<s> who can build the likes of which but you deserve your briefly take a look likes of which you a person s faith has been has been sort of go like refused to look at depend on us </s>\n",
            "<s> these planes are know that e mails mitt and you just all of it </s>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgEbwznc8A4C",
        "colab_type": "text"
      },
      "source": [
        "**Observation : Readability of quadgram > trigram > bigram > unigram**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwhqqEw24LPN",
        "colab_type": "text"
      },
      "source": [
        "**Neural Language Modelling : LSTM and RNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArqzuB4Vq1Rl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Neural_training(data, model_name):\n",
        "  \n",
        "  max_length=20\n",
        "  sent_data=[['<s>']+line.split()[:max_length]+['</s>'] for line in data]\n",
        "  \n",
        "  word_model = gensim.models.Word2Vec(sent_data, size=10, min_count=1, iter=100)\n",
        "  trained_vocabs = word_model.wv.vocab\n",
        "  trained_weights = np.array(word_model.wv.vectors)\n",
        "  vocab_size = word_model.wv.vectors.shape[0]\n",
        "  embedding_size = word_model.wv.vectors.shape[1]\n",
        "  \n",
        "  model = Sequential()\n",
        "  model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, weights=[trained_weights]))\n",
        "  if(model_name=='LSTM'):\n",
        "    model.add(LSTM(units=embedding_size))\n",
        "  if(model_name=='RNN'):\n",
        "    model.add(SimpleRNN(units=embedding_size))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(units=vocab_size))\n",
        "  model.add(Activation('softmax'))\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "  \n",
        "  corpus=[]\n",
        "  for i, line in enumerate(sent_data):\n",
        "    for j in range(2, len(line)):\n",
        "      corpus.append(line[:j])\n",
        "  \n",
        "  train_X = np.zeros([len(corpus), max_length+2], dtype=np.int32)\n",
        "  train_y = np.zeros([len(corpus)], dtype=np.int32)\n",
        "  for i, line in enumerate(corpus):\n",
        "    for j, word in enumerate(line[:-1]):\n",
        "      train_X[i, j] = word_model.wv.vocab[word].index\n",
        "    train_y[i]=word_model.wv.vocab[line[-1]].index\n",
        "  model.fit(train_X, train_y, batch_size=128, epochs=5)\n",
        "  \n",
        "  return (word_model, model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp5ytGuyYKt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Neural_generator(word_model, model):\n",
        "  x=['<s>']\n",
        "  i=0\n",
        "  while(i<=10):\n",
        "    i=i+1\n",
        "    windex_x=[word_model.wv.vocab[word].index for word in x]\n",
        "    preds = model.predict(x=np.array([windex_x]))\n",
        "    preds=preds/preds.sum()\n",
        "    p = np.random.multinomial(1, preds[0], 1)\n",
        "    idx = np.argmax(p)\n",
        "    w=word_model.wv.index2word[idx]\n",
        "    if(w=='</s>'):\n",
        "      x.append(w)\n",
        "      break\n",
        "    else:\n",
        "      x.append(w)\n",
        "      pass\n",
        "  return(' '.join(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcnamchlltCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Neural_perplexity(model, test):\n",
        "  \n",
        "  max_length=20\n",
        "  sent_data=[['<s>']+line.split()[:max_length]+['</s>'] for line in test]\n",
        "  \n",
        "  word_model = gensim.models.Word2Vec(sent_data, size=10, min_count=1, iter=100)\n",
        "  trained_vocabs = word_model.wv.vocab\n",
        "  trained_weights = np.array(word_model.wv.vectors)\n",
        "  vocab_size = word_model.wv.vectors.shape[0]\n",
        "  embedding_size = word_model.wv.vectors.shape[1]\n",
        "  \n",
        "  corpus=[]\n",
        "  for i, line in enumerate(sent_data):\n",
        "    for j in range(2, len(line)):\n",
        "      corpus.append(line[:j])\n",
        "        \n",
        "  N=len(corpus)\n",
        "  perplexity=0\n",
        "  for i, line in enumerate(corpus):\n",
        "    x=line[:-1]\n",
        "    y=line[-1]\n",
        "    windex_x=[word_model.wv.vocab[word].index for word in x]\n",
        "    preds=model.predict(x=np.array([windex_x]))\n",
        "    idx=word_model.wv.vocab[y].index\n",
        "    prob=preds[0][idx]\n",
        "    perplexity=perplexity-(math.log(prob)/N)\n",
        "  perplexity=math.exp(perplexity)\n",
        "  \n",
        "  return perplexity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5HMBM_o4Tdq",
        "colab_type": "text"
      },
      "source": [
        "**Random Text Generation of Neural Models using start words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O--8qZ9JXFVX",
        "colab_type": "code",
        "outputId": "51a8539a-41e2-4275-b4d0-74ad87b903ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "rnn_word_model, rnn_model =Neural_training(train, 'RNN')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "127009/127009 [==============================] - 28s 220us/step - loss: 6.3952\n",
            "Epoch 2/5\n",
            "127009/127009 [==============================] - 27s 213us/step - loss: 5.9917\n",
            "Epoch 3/5\n",
            "127009/127009 [==============================] - 27s 212us/step - loss: 5.9867\n",
            "Epoch 4/5\n",
            "127009/127009 [==============================] - 27s 211us/step - loss: 5.9834\n",
            "Epoch 5/5\n",
            "127009/127009 [==============================] - 25s 199us/step - loss: 5.9843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnvKN6We_oNL",
        "colab_type": "code",
        "outputId": "bc6d9320-316c-4f94-c2fc-588067118d8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "lstm_word_model, lstm_model =Neural_training(train, 'LSTM')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "127009/127009 [==============================] - 41s 321us/step - loss: 6.3455\n",
            "Epoch 2/5\n",
            "127009/127009 [==============================] - 37s 288us/step - loss: 5.9558\n",
            "Epoch 3/5\n",
            "127009/127009 [==============================] - 38s 299us/step - loss: 5.8646\n",
            "Epoch 4/5\n",
            "127009/127009 [==============================] - 40s 312us/step - loss: 5.7888\n",
            "Epoch 5/5\n",
            "127009/127009 [==============================] - 40s 315us/step - loss: 5.7237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS87t37b7ESp",
        "colab_type": "code",
        "outputId": "40fe141b-996d-4e92-ef02-31c3fdcde627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(\"Generation text : RNN\")\n",
        "for i in range(5):\n",
        "  print(Neural_generator(rnn_word_model, rnn_model))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generation text : RNN\n",
            "<s> subsidies veterans grid veteran screaming world non donors arkansas fraud re\n",
            "<s> m bring poker job laws gates deductible scum cheerleader hostile opinion\n",
            "<s> year fellas babies have doubt fellas more equipment while making artificially\n",
            "<s> t saying have follows we being sought local ozone history reinvigorate\n",
            "<s> proud emails this we raised speaking of her practiced nevada they\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMwGrNzf3IKW",
        "colab_type": "code",
        "outputId": "ef33bdd2-a585-4a3f-90de-197c96b30f6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(\"Generation text : LSTM\")\n",
        "for i in range(5):\n",
        "  print(Neural_generator(lstm_word_model, lstm_model))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generation text : LSTM\n",
            "<s> seeing look s from insist the space going gen nice settled\n",
            "<s> hope require fantastic day year exercise gorgeous phoenix starts fantasy elected\n",
            "<s> candidates 5 listen sometimes yes in peanuts of tur joining victory\n",
            "<s> cities terrific famous made 60 truck friend 24 certainly instincts indie\n",
            "<s> crowds cities 7 schuster poll bullets anger highest land monstrous kristol\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDDTYfXO8kiR",
        "colab_type": "text"
      },
      "source": [
        "**Observation : Readabilty of LSTM > RNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8ObTQEp0qRr",
        "colab_type": "text"
      },
      "source": [
        "**Perplexity of Neural Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m0bAoeqrC7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p_rnn=Neural_perplexity(rnn_model, test)\n",
        "p_lstm=Neural_perplexity(lstm_model, test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKlBsXJNrRGe",
        "colab_type": "code",
        "outputId": "a541a924-1fa3-48f6-8f4b-7b7eefb1fb5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Perplexity RNN : \"+str(p_rnn))\n",
        "print(\"Perplexity LSTM : \"+str(p_lstm))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perplexity RNN : 927.2233875816244\n",
            "Perplexity LSTM : 762.466345402934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8TdAHovwaRZ",
        "colab_type": "text"
      },
      "source": [
        "**Observation : Perplexity of RNN > LSTM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a76U-P-FncRK",
        "colab_type": "text"
      },
      "source": [
        "**Neural Models perform better than Classical Models. Because of the recurrence property of these RNN Models. It can be shown through the low perplexities of neural models compared to classic models based on the fact that model is better when perplexity is low.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8t6Pio27G8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}